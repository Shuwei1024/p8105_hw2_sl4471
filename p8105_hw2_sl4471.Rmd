---
title: "p8105 homework2"
author: "Shuwei Liu sl4471"
date: 2018-10-03
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Problem 1

## 1.1 Import data

```{r import_data_of_P1}
subway_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry,
         vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, `YES` = TRUE, `NO` = FALSE))
subway_df
```

## 1.2 Describe the data

```{r variables_and_dim}
variable.names(subway_df)
dim(subway_df)
```

This 1868 rows*19 columns data frame contains 19 variables, including "line", "station name", "station latitidu", "station longitude", "route1"-"route11", "entry", "vending", "entrance type", "ada" and "ada notes". After reading files, I use "janitor::clean_names()" to clean up variable names and covert them to lower snake case. And then, applying "select" function to choose the column I want. Finally, "mutate" function is used to convert the entry variable to a logical one. However, this data frame is not tidy yet. The different route numbers make it difficult to read.


```{r numbers_and_proportion}
count(distinct(subway_df, line, station_name))

ada_data = filter(subway_df, ada == TRUE)
count(distinct(ada_data, line, station_name))

without_vending = filter(subway_df, vending == "NO")
sum(without_vending$entry == TRUE)/length(without_vending$entry)
```

As above, there are 465 distinct stations, and 84 of them are ADA compliant. About 37.7% of station entrances / exits do not have vending allow entrance.

## 1.3 Reformat the data

```{r tidy_data}
subway_tidy = 
  gather(subway_df, key = "route_number", value = "route_name", route1:route11)
subway_tidy
```

Now, the route number and the route name are two distinct variables.

```{r A_line}
A_line = filter(subway_tidy, route_name == "A") %>% 
  distinct(line, station_name, ada)
nrow(A_line)
count(A_line, ada == "TRUE")
```

Obviously, there are 60 stations that serve A line and 17 of them are ADA compliant.

# Problem 2

## 2.1 Import data of MR.Trash Wheel

```{r import_data_of_P2}
wheel_df = 
  readxl::read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
                     sheet = 1, range = "A2:N338") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(round(sports_balls)))
wheel_df
```

## 2.2 Import precipitation data

```{r precipitation_data}
precipitation_2016 = 
  readxl::read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
                     sheet = 5, range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(total)) %>% 
  mutate(year = "2016") %>% 
  select(year, everything())

precipitation_2017 = 
  readxl::read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
                     sheet = 4, range = "A2:B14") %>% 
  janitor::clean_names() %>% 
  filter(!is.na(total)) %>% 
  mutate(year = "2017") %>% 
  select(year, everything())

precipitation_df = 
  bind_rows(precipitation_2016, precipitation_2017) %>%
  mutate(month = month.name[month])
precipitation_df
```

## 2.3 Data description

```{r wheel_in_2016}
wheel_2016 = 
  filter(wheel_df, year == 2016) 
```

The "wheel_df" tells us different kinds of trash in dumsters from year 2014-2018. It contains `r nrow(wheel_df)` observations with `r ncol(wheel_df)` variables. The key variable here is "dumpster".

The "precipitation_df" tells us the precipitation of every month in 2016-2017. It contains `r nrow(precipitation_df)` observations with `r ncol(precipitation_df)` variables. The key variable here is "year".

From the data, we can observe that the total precipitation in 2017 is `r sum(precipitation_2017$total)`. The median number of sports balls in a dumpster in 2016 is `r median(wheel_2016$sports_balls)`.

# Problem 3

## 3.1 Import data

```{r import_data_of_p3}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data("brfss_smart2010")
overall_health_data = 
  janitor::clean_names(brfss_smart2010) %>% 
  filter(topic == "Overall Health") %>% 
  select(-"class", -"topic", -"question", -"sample_size",
         -"confidence_limit_low":-"geo_location") %>% 
  spread(key = "response", value = data_value) %>% 
  janitor::clean_names() %>% 
  select(year, locationabbr, locationdesc, excellent, very_good, good, fair, poor) %>% 
  mutate(proportion = (excellent + very_good))
overall_health_data
```

## 3.2 An optional data frame

Kindly reminder: we are not asked to do this part.

According to the instructions of problem3, a data frame has been created. However, in my opinion, it is not reader-friendly. The "locationdesc" column repeat the "locationabbr" content. Therefore, I use another approach to modify it as below although it may not be necessary.

```{r optional_data_format}
overall_health_data0 = 
  janitor::clean_names(brfss_smart2010) %>% 
  filter(topic == "Overall Health") %>% 
  select(-"class", -"topic", -"question", -"sample_size",
         -"confidence_limit_low":-"geo_location") %>% 
  rename(state = locationabbr, location = locationdesc) %>% 
  separate(location, into = c("stateabbr", "location"), "- ") %>% 
  spread(key = "response", value = data_value) %>% 
  janitor::clean_names() %>% 
  select(year, state, location, excellent, very_good, good, fair, poor) %>% 
  mutate(proportion = (excellent + very_good))
overall_health_data0
```

## 3.3 Description of location

```{r distinct_location}
nrow(distinct(overall_health_data, locationabbr, locationdesc))
nrow(distinct(overall_health_data, locationabbr))
state_df = count(overall_health_data, locationabbr) %>% 
  arrange(desc(n))
state_df
```

As above, there are 404 unique locations in the dataset. Every state is presented, including Washington D.C. and 50 states of US. Among them, New Jersey has been observed the most with 142 observations.

## 3.4 Take median

```{r data_in_2002}
data_2002 = 
  filter(overall_health_data, year == 2002, !is.na(excellent))
```

In 2002, the median of the "Excellent" response value is `r median(data_2002$excellent)`.

## 3.5 Make plots

First, this plot shows the "Excellent" response values in the year 2002.

```{r ggplot1}
ggplot(data_2002, aes(x = excellent)) + 
  geom_histogram() +
  labs(
    title = "Excellent response values in 2002"
    ) +
  theme_bw()
```

Then, this is a scatterplot showing the proportion of "Excellent" response values in New York County and Queens County in each year from 2002 to 2010.

```{r ggplot2}
NY_data = 
  rename(overall_health_data, location = locationdesc) %>% 
  filter(location == "NY - New York County" | location == "NY - Queens County")

ggplot(NY_data, aes(x = year, y = excellent, color = location)) + 
  geom_point() +
  labs(
    title = "Excellent response values from 2002-2010",
    x = "year",
    y = "proportion of excellent response"
    ) +
  theme_bw() +
  theme(legend.position = "bottom")
```
